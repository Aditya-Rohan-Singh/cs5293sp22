{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7502f2-64f4-4871-b16e-c865529b3800",
   "metadata": {},
   "source": [
    "# Text Normalization\n",
    "Vocabulary large.\n",
    "A lot of repeated characters so effiency matters.\n",
    "Langauge is ambiguous so system can get confused.\n",
    "\n",
    "Tries to remove redundant or unnecessary information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6737d60-cff3-4d39-bb9a-dd58dc830c5e",
   "metadata": {},
   "source": [
    "## Remove Tags\n",
    "\n",
    "\"This is the <b>best</b> restaurant ever!\"\n",
    "\"This is the **best** restaurant ever!\"\n",
    "\n",
    "> BeautifulSoup/lxml\n",
    "> Regular Expressions\n",
    "\n",
    "Regex cannot detect and remove all HTML because HTML is not a regular language. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a6f7d-c785-4f5c-9c1f-1d4c7c9560c6",
   "metadata": {},
   "source": [
    "## Accented Characters.\n",
    "\n",
    "> Niño Brown vs Nino Brown\n",
    "> Niño -> Nino ?\n",
    "> Preserve unicode? Turn it into ASCII equivalent?\n",
    "> \\Sum vs E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc39687-3edb-479c-a096-cbd612b62588",
   "metadata": {},
   "source": [
    "## Expand Contractions\n",
    "\n",
    "> I'm going home -> I am going home\n",
    "> I [ain't] [gonna] do it -> I [am not] [going to] do it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798873c-b045-47d3-8386-d5716f8a2b2e",
   "metadata": {},
   "source": [
    "## Special Characters\n",
    "\n",
    "> I am sooo Happy 😁!! -> I am so happy !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef0965-49d7-427f-a664-bc69684463b0",
   "metadata": {},
   "source": [
    "## Stemming vs Lemmatization\n",
    "\n",
    "### Stem\n",
    "\n",
    "- Remove prefixes and suffixes from words and keeping only the base form.\n",
    "- base form of the word does not have to be a vocabulary word.\n",
    "\n",
    "> running -> run\n",
    "> thowing -> throw\n",
    "> carpet -> carp    <<\n",
    "> [dis]continue -> continue\n",
    "> [a]sham[ed] -> sham\n",
    "> begin[ing] -> begin\n",
    "\n",
    "Porter Stemmer \n",
    "Snowball Stemmer\n",
    "\n",
    "- Fast\n",
    "- Simple\n",
    "- Pretty accurate\n",
    "- May have tragic mistakes\n",
    "\n",
    "### Lemmatization\n",
    "\n",
    "- Converts a word to its root form based on its context and part of speech.\n",
    "- requires the part of speech and a dictionary.\n",
    "\n",
    "- Extremely accurate\n",
    "- Orders of magnitude slower than Stemming\n",
    "- Requires extra information (dictionary and p-o-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7d997-f7e7-4ea1-a296-bc03097d9516",
   "metadata": {},
   "source": [
    "## Removing Stop Words\n",
    "\n",
    "- Useless words\n",
    "\n",
    "> 'a', 'the', 'as'\n",
    "> URLS\n",
    "\n",
    "- functional words to help sentence structure but do not help with meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ecf14-19fd-469a-9c68-96bd4307602d",
   "metadata": {},
   "source": [
    "## Multilingual cleaning\n",
    "\n",
    "Can you detect the language?\n",
    "\n",
    "Options:\n",
    "\n",
    "1. Words can be translated into a common language\n",
    "2. Remove non-\"english\" text <- english centric appraoch could be problematic\n",
    "3. Use Universal Model\n",
    "\n",
    "Handling multple language requires care.\n",
    "\n",
    "Other language have stopwords and other langauge specific features that must be managed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bb0e2c-65f0-45fe-87b3-76eaf331d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy.lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f342821-5810-4a58-8613-891e9cba38ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'spacy.lang' has no attribute 'en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(spacy\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39men\u001b[38;5;241m.\u001b[39mstop_words\u001b[38;5;241m.\u001b[39mSTOP_WORDS)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'spacy.lang' has no attribute 'en'"
     ]
    }
   ],
   "source": [
    "print(spacy.lang.en.stop_words.STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5575e-e580-45d6-b37d-4aae8af3fa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
